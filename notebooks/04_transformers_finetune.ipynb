{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-09-01T16:35:30.549637Z",
     "iopub.status.busy": "2025-09-01T16:35:30.549369Z",
     "iopub.status.idle": "2025-09-01T16:35:30.557353Z",
     "shell.execute_reply": "2025-09-01T16:35:30.556728Z",
     "shell.execute_reply.started": "2025-09-01T16:35:30.549616Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "X_train = pd.read_csv('../data/processed/splits transformed/X_train_clean.csv', quoting= 1)\n",
    "X_test = pd.read_csv('../data/processed//splits transformed/X_test_clean.csv', quoting=1)\n",
    "\n",
    "y_train = pd.read_csv('../data/processed//splits/y_train.csv')\n",
    "y_test = pd.read_csv('../data/processed//splits/y_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "- By default, no cleaning required for Transformer Based Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-01T16:35:36.961533Z",
     "iopub.status.busy": "2025-09-01T16:35:36.961119Z",
     "iopub.status.idle": "2025-09-01T16:35:37.609154Z",
     "shell.execute_reply": "2025-09-01T16:35:37.608580Z",
     "shell.execute_reply.started": "2025-09-01T16:35:36.961507Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# cleaning\n",
    "def clean_text(text):\n",
    "    return text\n",
    "\n",
    "# train set cleaning\n",
    "X_train['transformed_title'] = X_train['title'].apply(clean_text)\n",
    "X_train['transformed_text'] = X_train['text'].apply(clean_text)\n",
    "X_train['transformed_text_title_combined'] = X_train['transformed_text'] + \" \" + X_train['transformed_title']\n",
    "\n",
    "# test set cleaning\n",
    "X_test['transformed_title'] = X_test['title'].apply(clean_text)\n",
    "X_test['transformed_text'] = X_test['text'].apply(clean_text)\n",
    "X_test['transformed_text_title_combined'] = X_test['transformed_text'] + \" \" + X_test['transformed_title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-01T19:37:15.766010Z",
     "iopub.status.busy": "2025-09-01T19:37:15.765496Z",
     "iopub.status.idle": "2025-09-01T19:37:15.775369Z",
     "shell.execute_reply": "2025-09-01T19:37:15.774722Z",
     "shell.execute_reply.started": "2025-09-01T19:37:15.765989Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>transformed_title</th>\n",
       "      <th>transformed_text</th>\n",
       "      <th>transformed_text_title_combined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18202</th>\n",
       "      <td>WATCH: PARTY GIRL MALIA OBAMA Caught On Camera...</td>\n",
       "      <td>B b but Baron Trump wore a t-shirt that said  ...</td>\n",
       "      <td>watch: party girl malia obama caught on camera...</td>\n",
       "      <td>b b but baron trump wore a t-shirt that said  ...</td>\n",
       "      <td>b b but baron trump wore a t-shirt that said  ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "18202  WATCH: PARTY GIRL MALIA OBAMA Caught On Camera...   \n",
       "\n",
       "                                                    text  \\\n",
       "18202  B b but Baron Trump wore a t-shirt that said  ...   \n",
       "\n",
       "                                       transformed_title  \\\n",
       "18202  watch: party girl malia obama caught on camera...   \n",
       "\n",
       "                                        transformed_text  \\\n",
       "18202  b b but baron trump wore a t-shirt that said  ...   \n",
       "\n",
       "                         transformed_text_title_combined  \n",
       "18202  b b but baron trump wore a t-shirt that said  ...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-01T16:35:39.929095Z",
     "iopub.status.busy": "2025-09-01T16:35:39.928809Z",
     "iopub.status.idle": "2025-09-01T16:35:39.937399Z",
     "shell.execute_reply": "2025-09-01T16:35:39.936807Z",
     "shell.execute_reply.started": "2025-09-01T16:35:39.929075Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>transformed_title</th>\n",
       "      <th>transformed_text</th>\n",
       "      <th>transformed_text_title_combined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31041</th>\n",
       "      <td>Clinton's charity confirms Qatar's $1 million ...</td>\n",
       "      <td>NEW YORK (Reuters) - The Clinton Foundation ha...</td>\n",
       "      <td>clinton's charity confirms qatar's $1 million ...</td>\n",
       "      <td>new york (reuters) - the clinton foundation ha...</td>\n",
       "      <td>new york (reuters) - the clinton foundation ha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "31041  Clinton's charity confirms Qatar's $1 million ...   \n",
       "\n",
       "                                                    text  \\\n",
       "31041  NEW YORK (Reuters) - The Clinton Foundation ha...   \n",
       "\n",
       "                                       transformed_title  \\\n",
       "31041  clinton's charity confirms qatar's $1 million ...   \n",
       "\n",
       "                                        transformed_text  \\\n",
       "31041  new york (reuters) - the clinton foundation ha...   \n",
       "\n",
       "                         transformed_text_title_combined  \n",
       "31041  new york (reuters) - the clinton foundation ha...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer Based Model - DistilBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-01T18:23:50.301397Z",
     "iopub.status.busy": "2025-09-01T18:23:50.300813Z",
     "iopub.status.idle": "2025-09-01T18:53:18.399010Z",
     "shell.execute_reply": "2025-09-01T18:53:18.398210Z",
     "shell.execute_reply.started": "2025-09-01T18:23:50.301374Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "820799a624de4ef0a4c72a9da28420a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/35918 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e399248b33054d7ba0d0b8165537a496",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8980 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "/tmp/ipykernel_36/1362134757.py:48: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3369' max='3369' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3369/3369 28:49, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.015300</td>\n",
       "      <td>0.004370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000929</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import DataCollatorWithPadding, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "import torch\n",
    "\n",
    "# 1. Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "# 2. Convert your dataset into Hugging Face Dataset format\n",
    "# Assume X_train, y_train, X_test, y_test are pandas Series\n",
    "train_ds = Dataset.from_dict({\"text\": list(X_train['transformed_text_title_combined']), \"label\": y_train['label'].tolist()})\n",
    "test_ds = Dataset.from_dict({\"text\": list(X_test['transformed_text_title_combined']), \"label\": y_test['label'].tolist()})\n",
    "\n",
    "# 3. Tokenization\n",
    "def tokenize_function(batch):\n",
    "    return tokenizer(batch[\"text\"], truncation=True, padding=True, max_length=256)\n",
    "\n",
    "tokenized_train = train_ds.map(tokenize_function, batched=True)\n",
    "tokenized_test = test_ds.map(tokenize_function, batched=True)\n",
    "\n",
    "# 4. Load pre-trained DistilBERT for binary classification\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased\", num_labels=2\n",
    ")\n",
    "\n",
    "# 5. Data collator\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "# 6. Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "        learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy=\"epoch\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    logging_dir=\"./logs\",\n",
    ")\n",
    "\n",
    "# 7. Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_test,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "# 8. Train (Fine-Tuning)\n",
    "trainer.train()\n",
    "\n",
    "# 9. Save fine-tuned model\n",
    "trainer.save_model(\"distilbert-fake-news\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-01T18:53:43.343456Z",
     "iopub.status.busy": "2025-09-01T18:53:43.342946Z",
     "iopub.status.idle": "2025-09-01T18:54:29.006901Z",
     "shell.execute_reply": "2025-09-01T18:54:29.006327Z",
     "shell.execute_reply.started": "2025-09-01T18:53:43.343433Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_36/732711365.py:18: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='281' max='281' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [281/281 00:45]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0007231914787553251, 'eval_accuracy': 0.9998886414253898, 'eval_precision': 1.0, 'eval_recall': 0.9997665732959851, 'eval_f1': 0.999883273024396, 'eval_runtime': 45.6446, 'eval_samples_per_second': 196.737, 'eval_steps_per_second': 6.156}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import numpy as np\n",
    "\n",
    "# Define metric computation\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "    }\n",
    "\n",
    "# Re-create trainer with compute_metrics\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_test,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Evaluate on test set\n",
    "results = trainer.evaluate()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-01T19:47:27.903514Z",
     "iopub.status.busy": "2025-09-01T19:47:27.902949Z",
     "iopub.status.idle": "2025-09-01T19:47:28.378631Z",
     "shell.execute_reply": "2025-09-01T19:47:28.377651Z",
     "shell.execute_reply.started": "2025-09-01T19:47:27.903494Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: \n",
      "    Israel has stepped up its destruction of Gaza City as it plans to seize Gaza’s largest urban centre and forcibly displace around one million Palestinians to concentration zones in the south, as it killed at least 78 people across the besieged enclave since dawn, including 32 desperately seeking food.\n",
      "    On Sunday, in Gaza City, the Palestinian Civil Defence reported a fire in tents near al-Quds Hospital after Israeli shelling. At least five people were killed and three wounded when a residential apartment was hit near the Remal neighbourhood.\n",
      "    \n",
      "Prediction: Real\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Text: Shocking news! Alien spaceship lands in New York and government covers it up.\n",
      "Prediction: Fake\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Text: President announces major healthcare reforms to support low-income families.\n",
      "Prediction: Real\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Text: You won’t believe this! Miracle cure for cancer discovered in secret lab.\n",
      "Prediction: Fake\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Text: \n",
      "    Hamas used sexual violence as \"part of a deliberate genocidal strategy\" during the 7 October 2023 attack on Israel, an all-women group of Israeli legal and gender experts allege in a new report calling for justice.\n",
      "    The Dinah Project says the report is based on a review of evidence including first-hand testimony from a survivor of an attempted rape and 15 former hostages held in Gaza, as well as accounts from witnesses to sexual assaults.\n",
      "    It lays out what the group describes as \"a legal blueprint for prosecuting these crimes, even when direct attribution to individual perpetrators is impossible\".\n",
      "    \n",
      "Prediction: Fake\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Text: \n",
      "    The Dinah Project says the accounts from people who saw or heard incidents of sexual violence showed that such crimes were \"widespread and systematic\" on 7 October.\n",
      "    According to the report, five witnesses reported at least four separate cases of gang rape; seven reported at least eight other separate cases of rape or severe sexual assaults, some of them in captivity; five reported at least three separate cases of sexual assaults, some in captivity; and three reported three separate cases of mutilation.\n",
      "    Nine of those cases related to the Nova music festival, two to the Nahal Oz military base, one to the Route 232 road, and four to incidents occurring in captivity in Gaza, the report says.\n",
      "    Twenty-seven first responders meanwhile described dozens of cases which showed \"clear signs of sexual violence across six locations\", the report says - the Nova festival, Route 232, and the kibbutzim of Be'eri, Alumim, Nahal Oz and Re'im.\n",
      "    The report also says that \"most victims were permanently silenced\", because they were either killed on 7 October or left too traumatised to talk.\n",
      "    In response, the authors provide what they describe as the \"first global legal blueprint explaining how to prosecute sexual violence as a weapon of war - even when evidence is messy, survivors are gone, and individual perpetrators can't be tied to individual acts\".\n",
      "    That includes an evidentiary framework to categorise information based on its proximity to incidents and its evidentiary value, and a legal framework for establishing criminal responsibility for atrocities committed during mass attacks, even when an individual did not personally commit each specific act or were not aware of its commission by someone else.\n",
      "    The report concludes by saying that justice is \"essential not only for individual victims but for affirming broader principles: that sexual violence in conflict is a serious violation of international law, that perpetrators will be held accountable, and that the international community will not allow such crimes to be committed with impunity\".\n",
      "    \n",
      "Prediction: Fake\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "# Load model + tokenizer\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-fake-news\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-fake-news\")\n",
    "\n",
    "# Put model in eval mode\n",
    "model.eval()\n",
    "\n",
    "# Example news texts\n",
    "samples = [\n",
    "    \"\"\"\n",
    "    Israel has stepped up its destruction of Gaza City as it plans to seize Gaza’s largest urban centre and forcibly displace around one million Palestinians to concentration zones in the south, as it killed at least 78 people across the besieged enclave since dawn, including 32 desperately seeking food.\n",
    "    On Sunday, in Gaza City, the Palestinian Civil Defence reported a fire in tents near al-Quds Hospital after Israeli shelling. At least five people were killed and three wounded when a residential apartment was hit near the Remal neighbourhood.\n",
    "    \"\"\", \n",
    "    \"Shocking news! Alien spaceship lands in New York and government covers it up.\",\n",
    "    \"President announces major healthcare reforms to support low-income families.\",\n",
    "    \"You won’t believe this! Miracle cure for cancer discovered in secret lab.\",  \n",
    "    \"\"\"\n",
    "    Hamas used sexual violence as \"part of a deliberate genocidal strategy\" during the 7 October 2023 attack on Israel, an all-women group of Israeli legal and gender experts allege in a new report calling for justice.\n",
    "    The Dinah Project says the report is based on a review of evidence including first-hand testimony from a survivor of an attempted rape and 15 former hostages held in Gaza, as well as accounts from witnesses to sexual assaults.\n",
    "    It lays out what the group describes as \"a legal blueprint for prosecuting these crimes, even when direct attribution to individual perpetrators is impossible\".\n",
    "    \"\"\",\n",
    "    \"\"\"\n",
    "    The Dinah Project says the accounts from people who saw or heard incidents of sexual violence showed that such crimes were \"widespread and systematic\" on 7 October.\n",
    "    According to the report, five witnesses reported at least four separate cases of gang rape; seven reported at least eight other separate cases of rape or severe sexual assaults, some of them in captivity; five reported at least three separate cases of sexual assaults, some in captivity; and three reported three separate cases of mutilation.\n",
    "    Nine of those cases related to the Nova music festival, two to the Nahal Oz military base, one to the Route 232 road, and four to incidents occurring in captivity in Gaza, the report says.\n",
    "    Twenty-seven first responders meanwhile described dozens of cases which showed \"clear signs of sexual violence across six locations\", the report says - the Nova festival, Route 232, and the kibbutzim of Be'eri, Alumim, Nahal Oz and Re'im.\n",
    "    The report also says that \"most victims were permanently silenced\", because they were either killed on 7 October or left too traumatised to talk.\n",
    "    In response, the authors provide what they describe as the \"first global legal blueprint explaining how to prosecute sexual violence as a weapon of war - even when evidence is messy, survivors are gone, and individual perpetrators can't be tied to individual acts\".\n",
    "    That includes an evidentiary framework to categorise information based on its proximity to incidents and its evidentiary value, and a legal framework for establishing criminal responsibility for atrocities committed during mass attacks, even when an individual did not personally commit each specific act or were not aware of its commission by someone else.\n",
    "    The report concludes by saying that justice is \"essential not only for individual victims but for affirming broader principles: that sexual violence in conflict is a serious violation of international law, that perpetrators will be held accountable, and that the international community will not allow such crimes to be committed with impunity\".\n",
    "    \"\"\"\n",
    "]\n",
    "\n",
    "labels = [\"Fake\", \"Real\"]\n",
    "\n",
    "for text in samples:\n",
    "    # Tokenize\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=256)\n",
    "\n",
    "    # Get predictions\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        predicted_class_id = torch.argmax(logits, dim=-1).item()\n",
    "\n",
    "    print(f\"Text: {text}\")\n",
    "    print(\"Prediction:\", labels[predicted_class_id])\n",
    "    print(\"-\" * 100)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 4831777,
     "sourceId": 8165591,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
